{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of SSD.ipynb","provenance":[{"file_id":"1t9vWPvpU-u8kLCOZ0srKHoPOyplyETMr","timestamp":1590640068019},{"file_id":"1RTNB6TK1d8G5dSSbUWRNwuUHd1Jw08d0","timestamp":1588526194034},{"file_id":"1e88ig_FMgGbws2t-l69bMj2Zbdg9oVLU","timestamp":1588478898463},{"file_id":"1tMpVtHcqzPaL96mm_vdkxf1PMs2ajrEx","timestamp":1588478829201}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JuVuuNb644wg","colab_type":"text"},"source":["## **Single Shot Detection**"]},{"cell_type":"code","metadata":{"id":"pKI1P_qb5E7U","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_2uEjri5E5P","colab_type":"code","colab":{}},"source":["#login with following credentials to have access to the drive\n","#userid :  bmyesu1@gmail.com\n","#password : Gvsaikumar2@ "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y6OxfAGg5K2L","colab_type":"text"},"source":["Necessary Installations"]},{"cell_type":"markdown","metadata":{"id":"vGn93W-ER4Tf","colab_type":"text"},"source":["For the object detection setup, necessary installation, tensoflow-gpu 1.15 and numpy 1.16 and other necessary libraries. Restart the Run time after installation"]},{"cell_type":"code","metadata":{"id":"T0_6I5P9Ufoh","colab_type":"code","outputId":"cfbd2f4e-fc4f-4eaa-f3a6-b6e8b18b177f","executionInfo":{"status":"ok","timestamp":1590640346756,"user_tz":-330,"elapsed":94828,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install --upgrade tensorflow-gpu==1.15\n","!pip install numpy==1.16\n","!pip install pillow lxml jupyter matplotlib cython"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==1.15\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n","\u001b[K     |████████████████████████████████| 411.5MB 37kB/s \n","\u001b[?25hCollecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n","Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.2.1)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 50.6MB/s \n","\u001b[?25hCollecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 49.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.1)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.10.0)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.29.0)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.9.0)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.34.2)\n","Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.0.8)\n","Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.18.4)\n","Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.0)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.2.2)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n","Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (46.3.0)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (2.10.0)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.6.0)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.1.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=4c930ca6b2c786a87f3320a094fcd199b65d4b71e091d778be610480f7768db2\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: gast, tensorboard, tensorflow-estimator, tensorflow-gpu\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorboard 2.2.1\n","    Uninstalling tensorboard-2.2.1:\n","      Successfully uninstalled tensorboard-2.2.1\n","  Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n","Collecting numpy==1.16\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/74/54c5f9bb9bd4dae27a61ec1b39076a39d359b3fb7ba15da79ef23858a9d8/numpy-1.16.0-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n","\u001b[K     |████████████████████████████████| 17.3MB 221kB/s \n","\u001b[31mERROR: umap-learn 0.4.3 has requirement numpy>=1.17, but you'll have numpy 1.16.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Found existing installation: numpy 1.18.4\n","    Uninstalling numpy-1.18.4:\n","      Successfully uninstalled numpy-1.18.4\n","Successfully installed numpy-1.16.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (4.2.6)\n","Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (1.0.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.18)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.6.1)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.2.2)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter) (4.10.1)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter) (7.5.1)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter) (4.7.4)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.16.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.8.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (3.1.5)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.4.4)\n","Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (2.11.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (4.3.3)\n","Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (5.0.6)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (2.1.3)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (1.4.2)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (4.6.3)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.6.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (5.3.4)\n","Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (4.5.3)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (0.2.0)\n","Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (0.8.3)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter) (5.5.0)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter) (3.5.1)\n","Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter) (19.0.1)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter) (1.9.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter) (1.0.18)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter) (20.4)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter) (0.5.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->jupyter) (1.1.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert->jupyter) (4.4.2)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert->jupyter) (2.6.0)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter) (0.6.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (0.8.1)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (4.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (46.3.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter) (0.1.9)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EwAzuy6f6ESf","colab_type":"text"},"source":["Make sure to restart the runtime before going further"]},{"cell_type":"code","metadata":{"id":"IK2ysuFo6Jya","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f9itCiSH6J9c","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2g9BFVBSTE6P","colab_type":"text"},"source":["\n","##   Downloading Tensoflow proto buffer"]},{"cell_type":"code","metadata":{"id":"Y_JDnCJrVcNw","colab_type":"code","outputId":"677fcee5-168c-455e-b3f9-f690efe8cbc2","executionInfo":{"status":"ok","timestamp":1590640377162,"user_tz":-330,"elapsed":14045,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}},"colab":{"base_uri":"https://localhost:8080/","height":663}},"source":["!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Selecting previously unselected package python-bs4.\n","(Reading database ... 144433 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MDmoh0GXyil9","colab_type":"text"},"source":["Guidelines:\n","This notebook has 3 parts\n","1. VISUALIZING THE RESULTS ON TENSORBOARD\n","2. RUNNING THE TRAINING\n","3. INFERENCING AND COUNTING NUMBER OF PRODUCTS\n","\n","As the model is being trained and saved, you can run 1 and 3 sections. if you wish to start training from scratch create a new folder and upload the sample train data, test data and annotations.txt file in the following directory tree.\n","\n","  \n","\n","```\n","\n","RandomSampleOf100Images.py  has code to sample train data.\n","\n","```\n","#Directory guide\n","```\n","\n",">gdrive\n","    >My Drive\n","      >object_detection\n","          >data\n","              >images #files in this folder needs to be uploaded\n","                  > train \n","                  > test\n","                  > annotations.txt\n","          > models\n","\n","```\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HaOLH8-7xxmx","colab_type":"text"},"source":["# 1. VISUALIZING THE RESULTS ON TENSORBOARD"]},{"cell_type":"markdown","metadata":{"id":"w5XJsGKjx9ax","colab_type":"text"},"source":["Run the following cells, a link is generated in the second cell output, clicking on that will open a tensorboard window.Past saved results can be viewed"]},{"cell_type":"code","metadata":{"id":"NydfN87Ixhu_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"b5c3f99e-534f-4491-ec82-b90428c20555","executionInfo":{"status":"ok","timestamp":1590640388768,"user_tz":-330,"elapsed":5728,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}}},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-05-28 04:34:29--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 34.238.5.126, 34.204.135.175, 52.6.123.150, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|34.238.5.126|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip’\n","\n","\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab   1%[                    ] 217.90K   828KB/s               \r        ngrok-stabl  20%[===>                ]   2.71M  5.86MB/s               \r       ngrok-stable  81%[===============>    ]  10.71M  16.1MB/s               \rngrok-stable-linux- 100%[===================>]  13.13M  18.0MB/s    in 0.7s    \n","\n","2020-05-28 04:34:30 (18.0 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lt9BGTdWxq8S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"decc411e-c7aa-4bd3-9fe8-2340153b253f","executionInfo":{"status":"ok","timestamp":1590643340289,"user_tz":-330,"elapsed":6158,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}}},"source":["#the logs that are created while training \n","LOG_DIR = \"training_1/\"\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","get_ipython().system_raw('./ngrok http 6006 &')\n","#The link to tensorboard.\n","#works after the training starts.\n","!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":43,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/usr/lib/python3.6/json/__init__.py\", line 299, in load\n","    parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n","  File \"/usr/lib/python3.6/json/__init__.py\", line 354, in loads\n","    return _default_decoder.decode(s)\n","  File \"/usr/lib/python3.6/json/decoder.py\", line 339, in decode\n","    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n","  File \"/usr/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n","    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n","json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AQxKGS0j6uJU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uu0SCDYw6uGX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qV-44AAn6uDi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Y9c42eg6uA8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NNn1Njd2SpLi","colab_type":"text"},"source":["Need to mount the google drive to save data, and object detetion tensorflow models. User credentials are provided in the cell"]},{"cell_type":"code","metadata":{"id":"KtyBtzV8_nGJ","colab_type":"code","outputId":"8ec69683-1086-44e8-b295-9d8acad0f2ee","executionInfo":{"status":"ok","timestamp":1590640418125,"user_tz":-330,"elapsed":23733,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QBOpGsAL67J2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"80722076-132a-46ee-e607-97a6e68f86d2","executionInfo":{"status":"ok","timestamp":1590641034923,"user_tz":-330,"elapsed":3342,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}}},"source":["!pwd"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/object_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mQxC0YiZ67OY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YEUdxBSp67-Q","colab_type":"code","colab":{}},"source":["import os\n","import glob\n","import pandas as pd\n","import xml.etree.ElementTree as ET\n","\n","\n","def xml_to_csv(path):\n","    xml_list = []\n","    for xml_file in glob.glob(path + '/*.xml'):\n","        tree = ET.parse(xml_file)\n","        root = tree.getroot()\n","        for member in root.findall('object'):\n","            value = (root.find('filename').text,\n","                     int(root.find('size')[0].text),\n","                     int(root.find('size')[1].text),\n","                     member[0].text,\n","                     int(member[4][0].text),\n","                     int(member[4][1].text),\n","                     int(member[4][2].text),\n","                     int(member[4][3].text)\n","                     )\n","            xml_list.append(value)\n","    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","    xml_df = pd.DataFrame(xml_list, columns=column_name)\n","    return xml_df\n","\n","\n","def main():\n","\t'''\n","    for directory in ['train','testing']:\n","        image_path = os.path.join(os.getcwd(), 'images/{}'.format(directory).format(directory))\n","        xml_df = xml_to_csv(image_path)\n","        xml_df.to_csv('data/{}_labels.csv'.format(directory), index=None)\n","        print('Successfully converted xml to csv.')\n","\t''' \n","\timage_path = os.path.join(os.getcwd(), 'images/train')\n","\txml_df = xml_to_csv(image_path)\n","\txml_df.to_csv('images/train_labels.csv', index=None)\n","\n","\timage_path = os.path.join(os.getcwd(), 'images/test')\n","\txml_df = xml_to_csv(image_path)\n","\txml_df.to_csv('images/test_labels.csv',index=None)\n","\n","main()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vYukDUQRmjfP","colab_type":"code","colab":{}},"source":["\"\"\"\n","Usage:\n","  # From tensorflow/models/\n","  # Create train data:\n","  python generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=train.record\n","  # Create test data:\n","  python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=test.record\n","\"\"\"\n","from __future__ import division\n","from __future__ import print_function\n","from __future__ import absolute_import\n","\n","import os\n","import io\n","import pandas as pd\n","import tensorflow as tf\n","\n","from PIL import Image\n","import sys\n","sys.path.append('../')\n","from object_detection.utils import dataset_util\n","from collections import namedtuple, OrderedDict\n","\n","flags = tf.app.flags\n","flags.DEFINE_string('csv_input', '', 'images/train_labels.csv')\n","flags.DEFINE_string('output_path', '', 'images/train.record')\n","flags.DEFINE_string('image_dir', '', 'images/train')\n","FLAGS = flags.FLAGS\n","\n","\n","# TO-DO replace this with label map\n","def class_text_to_int(row_label):\n","    if row_label == 1:\n","        return 1\n","    if row_label == 2:\n","        return 2\n","    else:\n","        return 0\n","\n","\n","def split(df, group):\n","    data = namedtuple('data', ['filename', 'object'])\n","    gb = df.groupby(group)\n","    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n","\n","\n","def create_tf_example(group, path):\n","    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n","        encoded_jpg = fid.read()\n","    encoded_jpg_io = io.BytesIO(encoded_jpg)\n","    image = Image.open(encoded_jpg_io)\n","    width, height = image.size\n","\n","    filename = group.filename.encode('utf8')\n","    image_format = b'jpg'\n","    xmins = []\n","    xmaxs = []\n","    ymins = []\n","    ymaxs = []\n","    classes_text = []\n","    classes = []\n","\n","    for index, row in group.object.iterrows():\n","        xmins.append(row['xmin'] / width)\n","        xmaxs.append(row['xmax'] / width)\n","        ymins.append(row['ymin'] / height)\n","        ymaxs.append(row['ymax'] / height)\n","        classes_text.append(row['class'].encode('utf8'))\n","        classes.append(class_text_to_int(row['class']))\n","\n","    tf_example = tf.train.Example(features=tf.train.Features(feature={\n","        'image/height': dataset_util.int64_feature(height),\n","        'image/width': dataset_util.int64_feature(width),\n","        'image/filename': dataset_util.bytes_feature(filename),\n","        'image/source_id': dataset_util.bytes_feature(filename),\n","        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","        'image/format': dataset_util.bytes_feature(image_format),\n","        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","        'image/object/class/label': dataset_util.int64_list_feature(classes),\n","    }))\n","    return tf_example\n","\n","\n","def main(_):\n","    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\n","    path = os.path.join(FLAGS.image_dir)\n","    examples = pd.read_csv(FLAGS.csv_input)\n","    grouped = split(examples, 'filename')\n","    for group in grouped:\n","        tf_example = create_tf_example(group, path)\n","        writer.write(tf_example.SerializeToString())\n","\n","    writer.close()\n","    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n","    print('Successfully created the TFRecords: {}'.format(output_path))\n","\n","\n","if __name__ == '__main__':\n","\ttf.app.run()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4w9oORQP6yvq","colab_type":"text"},"source":["# 2 .RUNNING THE TRAINING"]},{"cell_type":"code","metadata":{"id":"PnWfpdPQUybX","colab_type":"code","colab":{}},"source":["from __future__ import division, print_function, absolute_import\n","\n","import pandas as pd\n","import numpy as np\n","import csv\n","\n","import re\n","import os\n","import io\n","import glob\n","import shutil\n","import urllib.request\n","import tarfile\n","import xml.etree.ElementTree as ET\n","import tensorflow.compat.v1 as tf\n","import cv2 \n","from PIL import Image\n","from collections import namedtuple, OrderedDict\n","from google.colab import files"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BzXTVEhYBAbV","colab_type":"code","outputId":"a5e73927-d78a-4ad2-aca4-52de53434b42","executionInfo":{"status":"ok","timestamp":1590641435936,"user_tz":-330,"elapsed":1061,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["1.15.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2d2QzgYAxzRk","colab_type":"code","outputId":"2b10783c-0253-4512-ceaa-171bac7eead3","executionInfo":{"status":"ok","timestamp":1590640759239,"user_tz":-330,"elapsed":1073,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /gdrive/'My Drive'/"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rE6V7ptvUyEC","colab_type":"text"},"source":["Uncomment the following cell and create directory only if you want to work from scratch"]},{"cell_type":"code","metadata":{"id":"17wGAQbVxn2S","colab_type":"code","outputId":"c5fc13d0-5af9-456a-e839-ad393f816d29","executionInfo":{"status":"ok","timestamp":1588513248373,"user_tz":-330,"elapsed":5617,"user":{"displayName":"yesu b m","photoUrl":"","userId":"00628767656634862234"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#%mkdir object_detection"],"execution_count":0,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘object_detection’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x8JLoNCLVmkL","colab_type":"code","outputId":"dd0cb324-ff1f-4189-da0d-d268800212fa","executionInfo":{"status":"ok","timestamp":1590640765239,"user_tz":-330,"elapsed":1048,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /gdrive/'My Drive'/object_detection"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/object_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1WTpzLZaZyyv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WXhEQ5WPYaQj","colab_type":"text"},"source":["At /gdrive/My Drive/object_detection location \n","\n","1.   Create a folder data(cmd : !mkdir data)\n","2.   inside data create another floder images, and upload train, test and annotations file to this folder\n","\n"]},{"cell_type":"code","metadata":{"id":"duoJDiQKVO2-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c84nfsmZVPpb","colab_type":"text"},"source":["All the necessary models from the tensorflow has been downloaded, if you wish to start afresh uncomment and run the cell. before doing that delete the models folder from the drive"]},{"cell_type":"code","metadata":{"id":"9l29NLy9VxBg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a0936919-4ddc-4acd-80d7-3e033b3d6a3c","executionInfo":{"status":"ok","timestamp":1590640833198,"user_tz":-330,"elapsed":58811,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}}},"source":["!git clone --q https://github.com/tensorflow/models.git"],"execution_count":7,"outputs":[{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ywXe2ZxjVuIW","colab_type":"code","outputId":"f3ef82dd-bbca-4d65-d367-8c78c02a4022","executionInfo":{"status":"ok","timestamp":1590641394479,"user_tz":-330,"elapsed":1289,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd models/research/"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/object_detection/models/research\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yY5-_PCQVj79","colab_type":"text"},"source":["Here at models/research/ we compile the proto buffers and set enironmental variables with research and slim path"]},{"cell_type":"code","metadata":{"id":"DlB6AqYjXEWP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"968d06bf-6bdb-4c7f-e3ca-bba80607d93c","executionInfo":{"status":"ok","timestamp":1590641453537,"user_tz":-330,"elapsed":3596,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}}},"source":["import os\n","!protoc object_detection/protos/*.proto --python_out=.\n","os.environ['PYTHONPATH'] += ':./:./slim/'"],"execution_count":17,"outputs":[{"output_type":"stream","text":["object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"w5U3RG9YV4WX","colab_type":"text"},"source":["Run the next cell to see if the protos buffer and ENV variables are properly set"]},{"cell_type":"code","metadata":{"id":"fLO5PxkAXdK_","colab_type":"code","colab":{}},"source":["!python3 object_detection/builders/model_builder_test.py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jAeTGEVynvvI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"outputId":"8bec40fc-1ba0-4cfc-e94c-b73423314bcb","executionInfo":{"status":"ok","timestamp":1590641499687,"user_tz":-330,"elapsed":5182,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}}},"source":["!pip install tf_slim"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Collecting tf_slim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n","\u001b[K     |████████████████████████████████| 358kB 2.1MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.9.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.12.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RRkSlaFIWWTa","colab_type":"text"},"source":["# **Data Preparation**\n","The annotations provided were not adhering to the SSD annotations input in tensorflow\n","\n","Annotations from github were:\n","\n","eg. (image name, number of products, x (left top), y(left top), width(bounding box), height(bounding box), class)\n","\t\t\t\n","The above format is converted to:\n","\n","eg. (image name, width, height, class, xmin, ymin, xmax, ymax)\t\n","\n","xmin, ymin are same as x, y from github annotations.\n","\n","xmax is calculated as.\n","\n","```\n","xmax = xmin + 0.95*(widht of bounding box)\n","```\n","Have taken xmin+width of boouding box, as the boxes are adjacent to each other, there was a slight overlap in the bouding box region. To avoid that i took 0.95 times the width.\n","```\n","ymax = ymin + height of bounding box\n","```\n","**Note:\n","width -- full image width(not bounding box)\n","height -- full image height(not bounding box)"]},{"cell_type":"code","metadata":{"id":"Kl_VpvMBYNeM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZmBJAesbaOoN","colab_type":"text"},"source":["**Number of Classes:**\n","\n","In the given data we have 11 products of similar shape and sizes.\n","\t\tOur task is to predict whether there is a product or not in an image.\n","\n","\n","Since, we want to count the number of items, all we need to do is to classify the bounding box as empty or not. If it's not empty we would count it. So, I have put all 11 products under one class and 'empty space', as another  class(by default)."]},{"cell_type":"markdown","metadata":{"id":"0Kdv5DIdXmuk","colab_type":"text"},"source":["The annotations text file is converted to a train_labels.csv and test_labels.csv"]},{"cell_type":"code","metadata":{"id":"8eU-AOaxXnf-","colab_type":"code","outputId":"de0776ff-9aec-41cb-c242-20f7d704ed57","executionInfo":{"status":"ok","timestamp":1588591419326,"user_tz":-330,"elapsed":8039,"user":{"displayName":"yesu b m","photoUrl":"","userId":"00628767656634862234"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#file created here should save file in annotation as train_label.csv and train_label.csv\n","import pandas as pd\n","from PIL import Image\n","import os\n","import pandas as pd\n","\n","def text_annot_to_csv(IMAGE_PATH):\n","    img_annot = []\n","    train_annot = []\n","    test_annot = []\n","    train_set = set(os.listdir(IMAGE_PATH + \"/train/\"))\n","    test_set = set(os.listdir(IMAGE_PATH + \"/test/\"))   \n","    label_set = set()\n","    with open(IMAGE_PATH + \"/annotations.txt\", \"r\") as a_file:\n","        for line in a_file:\n","            img_annot = line.rstrip('\\n').split(' ')\n","            filename ,num = img_annot[:2]\n","            if (filename in train_set) or (filename in test_set):\n","              annot = img_annot[2:]\n","              for i in range(0, len(annot), 5):\n","                  xmin = int(annot[i:i+5][0]) \n","                  ymin = int(annot[i:i+5][1])\n","                  xmax = xmin + int((0.95)*int(annot[i:i+5][2]))\n","                  ymax = ymin + int(annot[i:i+5][3])\n","                  label = 'box'\n","                  label_set.add(label)\n","                  if filename in train_set:\n","                      im = Image.open(IMAGE_PATH + '/train/' + filename )\n","                      width, height = im.size\n","                      train_annot.append((filename, width, height, label, xmin, ymin, xmax, ymax))\n","                  else:\n","                      im = Image.open(IMAGE_PATH + '/test/' + filename )\n","                      width, height = im.size\n","                      test_annot.append((filename, width, height, label, xmin, ymin, xmax, ymax))\n","\n","    label_map_path = IMAGE_PATH + \"label_map.pbtxt\"\n","    pbtxt_content = \"\"\n","    for i, label in enumerate(label_set):\n","        pbtxt_content = ( pbtxt_content + \"item {{\\n   name: '{0}' \\n    id: {1}\\n}}\\n\\n\".format(label, i+1))\n","    pbtxt_content = pbtxt_content.strip()\n","    with open(label_map_path, \"w\") as f:\n","        f.write(pbtxt_content)\n","    return train_annot, test_annot\n","\t\n","def main():\n","\n","\tIMAGE_PATH = '/gdrive/My Drive/object_detection/images/'\n","\t\t\t\t\t\t\n","\tOUTPUT_DIR = '/gdrive/My Drive/object_detection/'\n","\n","\ttrain, test = text_annot_to_csv(IMAGE_PATH)\n","\t\n","\tcolumn_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","\ttrain_df = pd.DataFrame(train, columns=column_name)\n","\ttest_df = pd.DataFrame(test, columns= column_name)\n","\ttrain_df.to_csv(OUTPUT_DIR + '/train_labels.csv', index=None)\n","\ttest_df.to_csv(OUTPUT_DIR + '/test_labels.csv', index=None)\n","\tprint(\"---Successfully converted---\")\n","\t\n","if __name__ == '__main__':\n","\tmain()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["---Successfully converted---\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U71nKcJwaojs","colab_type":"text"},"source":["**Generating TF Recodrs.**\n","\n","Tensorflow accepts the data as TFRecords data.record. TFRecord is a binary file that runs fast with low memory usage."]},{"cell_type":"code","metadata":{"id":"bd5Is5W2ZuVy","colab_type":"code","outputId":"554d7159-87ae-4e38-a2d3-b3fdc365744d","executionInfo":{"status":"ok","timestamp":1590641589428,"user_tz":-330,"elapsed":3172,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["\n","from object_detection.utils import dataset_util\n","import pandas as pd\n","import io\n","import pandas as pd\n","import tensorflow as tf\n","import sys\n","from absl import app\n","from absl import flags\n","\n","from PIL import Image\n","from object_detection.utils import dataset_util\n","from collections import namedtuple, OrderedDict\n","data_base_url = '/gdrive/My Drive/object_detection/images/'\n","\n","image_dir = data_base_url \n","\n","def class_text_to_int(row_label):\n","\tif row_label == 1:  \n","\t\treturn 1\n","\telif row_label == 2:  \n","\t\treturn 2\n","\telse:\n","\t\treturn None\n","\n","def split(df, group):\n","  data = namedtuple('data', ['filename', 'object'])\n","  gb = df.groupby(group)\n","  return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n","\n","def create_tf_example(group, path):\n","\twith tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n","\t  encoded_jpg = fid.read()\n","\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n","\timage = Image.open(encoded_jpg_io)\n","\twidth, height = image.size\n","\tfilename = group.filename.encode('utf8')\n","\timage_format = b'jpg'\n","\txmins = []\n","\txmaxs = []\n","\tymins = []\n","\tymaxs = []\n","\tclasses_text = []\n","\tclasses = []\n","\n","\tfor index, row in group.object.iterrows():\n","\t\txmins.append(row['xmin'] / width)\n","\t\txmaxs.append(row['xmax'] / width)\n","\t\tymins.append(row['ymin'] / height)\n","\t\tymaxs.append(row['ymax'] / height)\n","\t\tclasses_text.append(str(row['class']).encode('utf8'))\n","\t\tclasses.append(class_text_to_int(row['class']))\n","\n","\ttf_example = tf.train.Example(features=tf.train.Features(feature={\n","\t\t'image/height': dataset_util.int64_feature(height),\n","\t\t'image/width': dataset_util.int64_feature(width),\n","\t\t'image/filename': dataset_util.bytes_feature(filename),\n","\t\t'image/source_id': dataset_util.bytes_feature(filename),\n","\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","\t\t'image/format': dataset_util.bytes_feature(image_format),\n","\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","\t\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n","\t\t}))\n","\treturn tf_example\n","\n","\n","for csv in ['train_labels', 'test_labels']:\n","  writer = tf.io.TFRecordWriter(data_base_url + csv + '.record')\n","  if csv == 'train_labels':\n","    path = os.path.join(image_dir+ '/train' )\n","  else:\n","    path = os.path.join(image_dir+ '/test' )\n","  examples = pd.read_csv(data_base_url + csv + '.csv')\n","  grouped = split(examples, 'filename')\n","  for group in grouped:\n","    tf_example = create_tf_example(group, path)\n","    writer.write(tf_example.SerializeToString())\n","    \n","  writer.close()\n","  output_path = os.path.join(os.getcwd(), data_base_url + csv + '.record')\n","  print('Successfully created the TFRecords: {}'.format(data_base_url +csv + '.record'))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Successfully created the TFRecords: /gdrive/My Drive/object_detection/images/train_labels.record\n","Successfully created the TFRecords: /gdrive/My Drive/object_detection/images/test_labels.record\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JtF552ogcUeI","colab_type":"text"},"source":["**Selecting and downloading the pre-trained models**"]},{"cell_type":"code","metadata":{"id":"Bhwg4zdmawTQ","colab_type":"code","colab":{}},"source":["MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","    },\n","    'ssd_inception_v2_coco':{\n","        'model_name': 'ssd_inception_v2_coco_2018_01_28',\n","    },\n","    \n","}\n","\n","selected_model = 'ssd_mobilenet_v2'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AO99UJLTgbjn","colab_type":"code","colab":{}},"source":["#the distination folder where the model will be saved\n","#change this if you have a different working dir\n","DEST_DIR = '/gdrive/My Drive/object_detection/models/research/pretrained_model'\n","\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","#selecting the model\n","MODEL_FILE = MODEL + '.tar.gz'\n","\n","#creating the downlaod link for the model selected\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","\n","#checks if the model has already been downloaded, download it otherwise\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","#unzipping the model and extracting its content\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","# creating an output file to save the model while training\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gMB4fooUcx8S","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"61Mzof1YiFu0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"acb8062f-7fda-4a4e-cd50-122c469ac2e2","executionInfo":{"status":"ok","timestamp":1590641964156,"user_tz":-330,"elapsed":1099,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}}},"source":["%cd /gdrive/My Drive/object_detection/models/research/"],"execution_count":34,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/object_detection/models/research\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Qd30o7O5dojh","colab_type":"text"},"source":["**Configuring the training Pipeline**"]},{"cell_type":"markdown","metadata":{"id":"kyBXbqIRdsLE","colab_type":"text"},"source":["Running the below cell gives a default config file of the pretrained model chosen. "]},{"cell_type":"code","metadata":{"id":"Lu61ax_zgiWF","colab_type":"code","outputId":"e66c1890-3f8a-4765-ccdc-e12042587ac8","executionInfo":{"status":"ok","timestamp":1590642110060,"user_tz":-330,"elapsed":3788,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!cat object_detection/samples/configs/ssd_mobilenet_v2_coco.config"],"execution_count":38,"outputs":[{"output_type":"stream","text":["# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n","# Users should configure the fine_tune_checkpoint field in the train config as\n","# well as the label_map_path and input_path fields in the train_input_reader and\n","# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n","# should be configured.\n","\n","model {\n","  ssd {\n","    num_classes: 90\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.95\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.3333\n","      }\n","    }\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        use_dropout: false\n","        dropout_keep_probability: 0.8\n","        kernel_size: 1\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            truncated_normal_initializer {\n","              stddev: 0.03\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            train: true,\n","            scale: true,\n","            center: true,\n","            decay: 0.9997,\n","            epsilon: 0.001,\n","          }\n","        }\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_mobilenet_v2'\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          train: true,\n","          scale: true,\n","          center: true,\n","          decay: 0.9997,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid {\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      hard_example_miner {\n","        num_hard_examples: 3000\n","        iou_threshold: 0.99\n","        loss_type: CLASSIFICATION\n","        max_negatives_per_positive: 3\n","        min_negatives_per_image: 3\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 24\n","  optimizer {\n","    rms_prop_optimizer: {\n","      learning_rate: {\n","        exponential_decay_learning_rate {\n","          initial_learning_rate: 0.004\n","          decay_steps: 800720\n","          decay_factor: 0.95\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","      decay: 0.9\n","      epsilon: 1.0\n","    }\n","  }\n","  fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED/model.ckpt\"\n","  fine_tune_checkpoint_type:  \"detection\"\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the pets dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 200000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","}\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"PATH_TO_BE_CONFIGURED/mscoco_train.record-?????-of-00100\"\n","  }\n","  label_map_path: \"PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  num_examples: 8000\n","  # Note: The below line limits the evaluation process to 10 evaluations.\n","  # Remove the below line to evaluate indefinitely.\n","  max_evals: 10\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"PATH_TO_BE_CONFIGURED/mscoco_val.record-?????-of-00010\"\n","  }\n","  label_map_path: \"PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"H773SF54d804","colab_type":"text"},"source":["Copy the output from the above cell and paste it below the command. Running this will let you modify the config file.\n","\n","Change the num of classes in model from 90 to 1.\n","\n","At anchor genrator, remove all aspect ratios and give only one value i.e 2.\n","\n","Paths to be modified are.\n","\n","1. fine tune checkpoint\n","2. train input reader\n","3. label map path\n","4. eval input reader\n","5. label map path\n","\n","At train config, add data augmentation to imporve the results\n","\n","After changing the above fields run the cell\n","\n"]},{"cell_type":"code","metadata":{"id":"9a0ZgQauqkvK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"55047aa6-322c-4115-af13-8cb1e1aa93ed","executionInfo":{"status":"ok","timestamp":1590643126703,"user_tz":-330,"elapsed":1103,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}}},"source":["%%writefile object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n","\n","# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n","# Users should configure the fine_tune_checkpoint field in the train config as\n","# well as the label_map_path and input_path fields in the train_input_reader and\n","# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n","# should be configured.\n","\n","model {\n","  ssd {\n","    num_classes: 2\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.95\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.3333\n","      }\n","    }\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        use_dropout: false\n","        dropout_keep_probability: 0.8\n","        kernel_size: 1\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            truncated_normal_initializer {\n","              stddev: 0.03\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            train: true,\n","            scale: true,\n","            center: true,\n","            decay: 0.9997,\n","            epsilon: 0.001,\n","          }\n","        }\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_mobilenet_v2'\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          train: true,\n","          scale: true,\n","          center: true,\n","          decay: 0.9997,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid {\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      hard_example_miner {\n","        num_hard_examples: 3000\n","        iou_threshold: 0.99\n","        loss_type: CLASSIFICATION\n","        max_negatives_per_positive: 3\n","        min_negatives_per_image: 3\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 24\n","  optimizer {\n","    rms_prop_optimizer: {\n","      learning_rate: {\n","        exponential_decay_learning_rate {\n","          initial_learning_rate: 0.004\n","          decay_steps: 800720\n","          decay_factor: 0.95\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","      decay: 0.9\n","      epsilon: 1.0\n","    }\n","  }\n","  fine_tune_checkpoint: \"/gdrive/My Drive/object_detection/models/research/pretrained_model/model.ckpt\"\n","  fine_tune_checkpoint_type:  \"detection\"\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the pets dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 200000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_vertical_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_pixel_value_scale {\n","    }\n","  }\n","}\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/gdrive/My Drive/object_detection/images/train_labels.record\"\n","  }\n","  label_map_path: \"/gdrive/My Drive/object_detection/images/label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  num_examples: 8000\n","  # Note: The below line limits the evaluation process to 10 evaluations.\n","  # Remove the below line to evaluate indefinitely.\n","  max_evals: 10\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/gdrive/My Drive/object_detection/images/test_labels.record\"\n","  }\n","  label_map_path: \"/gdrive/My Drive/object_detection/images/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}\n"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Overwriting object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-9Ze4b75gdjn","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"jEJjC1R9gd2K","colab_type":"text"},"source":["Running the next two cells will allow use to visualize the results in tensorboard"]},{"cell_type":"code","metadata":{"id":"EL8PdkoDjSJP","colab_type":"code","outputId":"67f2b70b-f16d-4fe9-da71-2f8a29f41901","executionInfo":{"status":"ok","timestamp":1588741767556,"user_tz":-330,"elapsed":6414,"user":{"displayName":"yesu b m","photoUrl":"","userId":"00628767656634862234"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-05-06 05:10:40--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 52.86.21.186, 3.213.66.77, 52.4.202.19, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|52.86.21.186|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip.5’\n","\n","ngrok-stable-linux- 100%[===================>]  13.13M  18.5MB/s    in 0.7s    \n","\n","2020-05-06 05:10:41 (18.5 MB/s) - ‘ngrok-stable-linux-amd64.zip.5’ saved [13773305/13773305]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XPT3wX8XhDPL","colab_type":"code","colab":{}},"source":["import json"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ntypJWC8gw_i","colab_type":"text"},"source":["The generated link after running the below cell will open a tensorboard window in a new tab."]},{"cell_type":"code","metadata":{"id":"U9G8aN7qjVoY","colab_type":"code","outputId":"6f1d68c1-c190-40f7-c53f-8155c96514a4","executionInfo":{"status":"ok","timestamp":1590650645222,"user_tz":-330,"elapsed":5050,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["#the logs that are created while training \n","LOG_DIR = \"training_1/\"\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","get_ipython().system_raw('./ngrok http 6006 &')\n","#The link to tensorboard.\n","#works after the training starts.\n","!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":63,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/usr/lib/python3.6/json/__init__.py\", line 299, in load\n","    parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n","  File \"/usr/lib/python3.6/json/__init__.py\", line 354, in loads\n","    return _default_decoder.decode(s)\n","  File \"/usr/lib/python3.6/json/decoder.py\", line 339, in decode\n","    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n","  File \"/usr/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n","    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n","json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kTFyqW1ZhSQd","colab_type":"text"},"source":["**Training**\n","\n","Running the cell will start the training, this will take a while"]},{"cell_type":"code","metadata":{"id":"UUzvXF4UjYJX","colab_type":"code","outputId":"d221d506-6ac1-4b83-fd01-127f77983a95","executionInfo":{"status":"error","timestamp":1590650674035,"user_tz":-330,"elapsed":27366,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python3 object_detection/model_main.py \\\n","    --pipeline_config_path=/gdrive/My\\ Drive/object_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config \\\n","    --model_dir=training_1/"],"execution_count":64,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0528 07:25:36.316220 140516147718016 model_lib.py:717] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting train_steps: None\n","I0528 07:25:36.316444 140516147718016 config_util.py:523] Maybe overwriting train_steps: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0528 07:25:36.316536 140516147718016 config_util.py:523] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n","I0528 07:25:36.316641 140516147718016 config_util.py:523] Maybe overwriting sample_1_of_n_eval_examples: 1\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0528 07:25:36.316723 140516147718016 config_util.py:523] Maybe overwriting eval_num_epochs: 1\n","INFO:tensorflow:Maybe overwriting load_pretrained: True\n","I0528 07:25:36.316794 140516147718016 config_util.py:523] Maybe overwriting load_pretrained: True\n","INFO:tensorflow:Ignoring config override key: load_pretrained\n","I0528 07:25:36.316869 140516147718016 config_util.py:533] Ignoring config override key: load_pretrained\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0528 07:25:36.317645 140516147718016 model_lib.py:733] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","I0528 07:25:36.317770 140516147718016 model_lib.py:768] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","INFO:tensorflow:Using config: {'_model_dir': 'training_1/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcc15dd4630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","I0528 07:25:36.318177 140516147718016 estimator.py:212] Using config: {'_model_dir': 'training_1/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcc15dd4630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fcbfb941488>) includes params argument, but params are not passed to Estimator.\n","W0528 07:25:36.318406 140516147718016 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fcbfb941488>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Not using Distribute Coordinator.\n","I0528 07:25:36.319265 140516147718016 estimator_training.py:186] Not using Distribute Coordinator.\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","I0528 07:25:36.319442 140516147718016 training.py:612] Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","I0528 07:25:36.319669 140516147718016 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0528 07:25:36.324918 140516147718016 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0528 07:25:36.358664 140516147718016 dataset_builder.py:84] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /gdrive/My Drive/object_detection/models/research/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","W0528 07:25:36.363438 140516147718016 deprecation.py:323] From /gdrive/My Drive/object_detection/models/research/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0528 07:25:36.363604 140516147718016 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","2020-05-28 07:25:37.874968: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-05-28 07:25:37.877252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:25:37.877772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-05-28 07:25:37.878041: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-05-28 07:25:37.879101: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-05-28 07:25:37.880815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-05-28 07:25:37.881155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-05-28 07:25:37.882566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-05-28 07:25:37.883832: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-05-28 07:25:37.887529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-05-28 07:25:37.887657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:25:37.888197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:25:37.888666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","WARNING:tensorflow:From /gdrive/My Drive/object_detection/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0528 07:25:46.730111 140516147718016 deprecation.py:323] From /gdrive/My Drive/object_detection/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /gdrive/My Drive/object_detection/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0528 07:25:46.831078 140516147718016 deprecation.py:323] From /gdrive/My Drive/object_detection/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0528 07:25:52.161154 140516147718016 api.py:332] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\n","    func_outputs = python_func(*func_args, **func_kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 2707, in wrapper_fn\n","    ret = _wrapper_helper(*args)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 2652, in _wrapper_helper\n","    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 234, in wrapper\n","    return converted_call(f, options, args, kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\n","    result = converted_f(*effective_args, **kwargs)\n","  File \"/tmp/tmp56kqdj7e.py\", line 26, in tf__transform_and_pad_input_data_fn\n","    tensor_dict = ag__.converted_call(pad_input_data_to_static_shapes, transform_and_pad_input_data_fn_scope.callopts, (), {'tensor_dict': ag__.converted_call(transform_data_fn, transform_and_pad_input_data_fn_scope.callopts, (tensor_dict,), None, transform_and_pad_input_data_fn_scope), 'max_num_boxes': train_input_config.max_number_of_boxes, 'num_classes': num_classes, 'spatial_image_shape': ag__.converted_call(config_util.get_spatial_image_size, transform_and_pad_input_data_fn_scope.callopts, (image_resizer_config,), None, transform_and_pad_input_data_fn_scope), 'max_num_context_features': ag__.converted_call(config_util.get_max_num_context_features, transform_and_pad_input_data_fn_scope.callopts, (model_config,), None, transform_and_pad_input_data_fn_scope), 'context_feature_length': ag__.converted_call(config_util.get_context_feature_length, transform_and_pad_input_data_fn_scope.callopts, (model_config,), None, transform_and_pad_input_data_fn_scope)}, transform_and_pad_input_data_fn_scope)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\n","    result = converted_f(*effective_args, **kwargs)\n","  File \"/tmp/tmpo8j06jdq.py\", line 216, in tf__transform_input_data\n","    preprocessed_resized_image, true_image_shape = ag__.converted_call(model_preprocess_fn, transform_input_data_scope.callopts, (ag__.converted_call(tf.expand_dims, transform_input_data_scope.callopts, (ag__.converted_call(tf.cast, transform_input_data_scope.callopts, (image,), {'dtype': tf.float32}, transform_input_data_scope),), {'axis': 0}, transform_input_data_scope),), None, transform_input_data_scope)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 541, in converted_call\n","    result = converted_f(*effective_args)\n","  File \"/tmp/tmphh7w_zz3.py\", line 32, in tf__preprocess\n","    resized_inputs, true_image_shapes = ag__.converted_call(shape_utils.resize_images_and_return_shapes, preprocess_scope.callopts, (inputs, self._image_resizer_fn), None, preprocess_scope)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 541, in converted_call\n","    result = converted_f(*effective_args)\n","  File \"/tmp/tmpv2e8adym.py\", line 42, in tf__resize_images_and_return_shapes\n","    outputs = ag__.converted_call(static_or_dynamic_map_fn, resize_images_and_return_shapes_scope.callopts, (image_resizer_fn,), {'elems': inputs, 'dtype': [tf.float32, tf.int32]}, resize_images_and_return_shapes_scope)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\n","    result = converted_f(*effective_args, **kwargs)\n","  File \"/tmp/tmpj88bck3r.py\", line 175, in tf__static_or_dynamic_map_fn\n","    outputs, retval_, do_return = ag__.if_stmt(cond_5, if_true_5, if_false_5, get_state_7, set_state_7, ('outputs', 'retval_', 'do_return'), ())\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 895, in if_stmt\n","    return _py_if_stmt(cond, body, orelse)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 1004, in _py_if_stmt\n","    return body() if cond else orelse()\n","  File \"/tmp/tmpj88bck3r.py\", line 172, in if_false_5\n","    outputs, retval__2, do_return_2 = ag__.if_stmt(cond_4, if_true_4, if_false_4, get_state_6, set_state_6, ('outputs', 'retval_', 'do_return'), ())\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 895, in if_stmt\n","    return _py_if_stmt(cond, body, orelse)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 1004, in _py_if_stmt\n","    return body() if cond else orelse()\n","  File \"/tmp/tmpj88bck3r.py\", line 169, in if_false_4\n","    outputs = [ag__.converted_call(fn, static_or_dynamic_map_fn_scope.callopts, (arg,), None, static_or_dynamic_map_fn_scope) for arg in ag__.converted_call(tf.unstack, static_or_dynamic_map_fn_scope.callopts, (elems,), None, static_or_dynamic_map_fn_scope)]\n","  File \"/tmp/tmpj88bck3r.py\", line 169, in <listcomp>\n","    outputs = [ag__.converted_call(fn, static_or_dynamic_map_fn_scope.callopts, (arg,), None, static_or_dynamic_map_fn_scope) for arg in ag__.converted_call(tf.unstack, static_or_dynamic_map_fn_scope.callopts, (elems,), None, static_or_dynamic_map_fn_scope)]\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 506, in converted_call\n","    converted_f = conversion.convert(target_entity, program_ctx)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 322, in convert\n","    free_nonglobal_var_names)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 252, in _convert_with_cache\n","    nodes, include_source_map=True)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/compiler.py\", line 138, in ast_to_object\n","    source_map = origin_info.create_source_map(nodes, source, module.__file__)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/origin_info.py\", line 105, in create_source_map\n","    reparsed_nodes = parser.parse_str(code, preamble_len=0, single_node=False)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 139, in parse_str\n","    module_node = gast.parse(src)\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/gast.py\", line 240, in parse\n","    return ast_to_gast(_ast.parse(*args, **kwargs))\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/ast3.py\", line 151, in ast_to_gast\n","    return Ast3ToGAst().visit(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 253, in visit\n","    return visitor(node)\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/astn.py\", line 24, in generic_visit\n","    setattr(new_node, field, self._visit(getattr(node, field)))\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/astn.py\", line 11, in _visit\n","    return [self._visit(n) for n in node]\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/astn.py\", line 11, in <listcomp>\n","    return [self._visit(n) for n in node]\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/astn.py\", line 13, in _visit\n","    return self.visit(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 253, in visit\n","    return visitor(node)\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/astn.py\", line 24, in generic_visit\n","    setattr(new_node, field, self._visit(getattr(node, field)))\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/astn.py\", line 11, in _visit\n","    return [self._visit(n) for n in node]\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/astn.py\", line 11, in <listcomp>\n","    return [self._visit(n) for n in node]\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/astn.py\", line 13, in _visit\n","    return self.visit(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 253, in visit\n","    return visitor(node)\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/astn.py\", line 24, in generic_visit\n","    setattr(new_node, field, self._visit(getattr(node, field)))\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/astn.py\", line 11, in _visit\n","    return [self._visit(n) for n in node]\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/astn.py\", line 11, in <listcomp>\n","    return [self._visit(n) for n in node]\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/astn.py\", line 13, in _visit\n","    return self.visit(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 253, in visit\n","    return visitor(node)\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/astn.py\", line 24, in generic_visit\n","    setattr(new_node, field, self._visit(getattr(node, field)))\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/astn.py\", line 13, in _visit\n","    return self.visit(node)\n","  File \"/usr/lib/python3.6/ast.py\", line 253, in visit\n","    return visitor(node)\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/astn.py\", line 22, in generic_visit\n","    new_node = getattr(to, cls)()\n","  File \"/usr/local/lib/python3.6/dist-packages/gast/gast.py\", line 15, in create_node\n","    for argname, argval in zip(self._fields, args):\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"object_detection/model_main.py\", line 114, in <module>\n","    tf.app.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"object_detection/model_main.py\", line 110, in main\n","    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n","    return executor.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n","    return self.run_local()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n","    saving_listeners=saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n","    loss = self._train_model(input_fn, hooks, saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n","    return self._train_model_default(input_fn, hooks, saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1188, in _train_model_default\n","    input_fn, ModeKeys.TRAIN))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1025, in _get_features_and_labels_from_input_fn\n","    self._call_input_fn(input_fn, mode))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1116, in _call_input_fn\n","    return input_fn(**kwargs)\n","  File \"/gdrive/My Drive/object_detection/models/research/object_detection/inputs.py\", line 664, in _train_input_fn\n","    params=params)\n","  File \"/gdrive/My Drive/object_detection/models/research/object_detection/inputs.py\", line 791, in train_input\n","    reduce_to_frame_fn=reduce_to_frame_fn)\n","  File \"/gdrive/My Drive/object_detection/models/research/object_detection/builders/dataset_builder.py\", line 171, in build\n","    tf.data.experimental.AUTOTUNE)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 1913, in map\n","    self, map_func, num_parallel_calls, preserve_cardinality=False))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3472, in __init__\n","    use_legacy_function=use_legacy_function)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 2713, in __init__\n","    self._function = wrapper_fn._get_concrete_function_internal()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1853, in _get_concrete_function_internal\n","    *args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1847, in _get_concrete_function_internal_garbage_collected\n","    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 2147, in _maybe_define_function\n","    graph_function = self._create_graph_function(args, kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 2038, in _create_graph_function\n","    capture_by_value=self._capture_by_value),\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 956, in func_graph_from_py_func\n","    func_graph.variables = variables\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/auto_control_deps.py\", line 292, in __exit__\n","    if control_flow_util.IsInWhileLoop(op):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_util.py\", line 82, in IsInWhileLoop\n","    def IsInWhileLoop(op):\n","KeyboardInterrupt\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-cf08aa156ae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python3 object_detection/model_main.py     --pipeline_config_path=/gdrive/My\\\\ Drive/object_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config     --model_dir=training_1/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"JLOobAoMo8Eq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"cbfbb8a0-9a9d-42e4-a2c4-5329417c1afa","executionInfo":{"status":"ok","timestamp":1590650753014,"user_tz":-330,"elapsed":3329,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}}},"source":["!pwd"],"execution_count":68,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/object_detection/models/research\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YhmG799Chk2F","colab_type":"text"},"source":["**Export the trained model.**\n","\n","Running export_inference_graph.py will convert the model to a frozen model frozen_inference_graph.pb that we can use for inference. "]},{"cell_type":"code","metadata":{"id":"Cn8rubR1je5b","colab_type":"code","colab":{}},"source":["\n","output_directory = './fine_tuned_model_1'\n","\n","lst = os.listdir('training_1')\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join('training_1', last_model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gyeQgNZcjjez","colab_type":"code","outputId":"56b4288f-e7ac-4fce-da96-db28b65764f3","executionInfo":{"status":"ok","timestamp":1590650838785,"user_tz":-330,"elapsed":16542,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python /gdrive/'My Drive'/object_detection/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path=/gdrive/My\\ Drive/object_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}"],"execution_count":72,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0528 07:28:31.957512 140206724724608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0528 07:28:33.956619 140206724724608 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0528 07:28:34.095474 140206724724608 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0528 07:28:34.135380 140206724724608 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0528 07:28:34.176989 140206724724608 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0528 07:28:34.214606 140206724724608 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0528 07:28:34.250285 140206724724608 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /gdrive/My Drive/object_detection/models/research/object_detection/core/post_processing.py:583: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0528 07:28:34.488425 140206724724608 deprecation.py:323] From /gdrive/My Drive/object_detection/models/research/object_detection/core/post_processing.py:583: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /gdrive/My Drive/object_detection/models/research/object_detection/exporter.py:400: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0528 07:28:34.825684 140206724724608 deprecation.py:323] From /gdrive/My Drive/object_detection/models/research/object_detection/exporter.py:400: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /gdrive/My Drive/object_detection/models/research/object_detection/exporter.py:555: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0528 07:28:34.828662 140206724724608 deprecation.py:323] From /gdrive/My Drive/object_detection/models/research/object_detection/exporter.py:555: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0528 07:28:34.829652 140206724724608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","135 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/4.59m params)\n","  BoxPredictor_0 (--/12.12k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n","    BoxPredictor_0/ClassPredictor (--/5.19k params)\n","      BoxPredictor_0/ClassPredictor/biases (9, 9/9 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x576x9, 5.18k/5.18k params)\n","  BoxPredictor_1 (--/53.80k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n","    BoxPredictor_1/ClassPredictor (--/23.06k params)\n","      BoxPredictor_1/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x1280x18, 23.04k/23.04k params)\n","  BoxPredictor_2 (--/21.55k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/ClassPredictor (--/9.23k params)\n","      BoxPredictor_2/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x18, 9.22k/9.22k params)\n","  BoxPredictor_3 (--/10.79k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/ClassPredictor (--/4.63k params)\n","      BoxPredictor_3/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x18, 4.61k/4.61k params)\n","  BoxPredictor_4 (--/10.79k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/ClassPredictor (--/4.63k params)\n","      BoxPredictor_4/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x18, 4.61k/4.61k params)\n","  BoxPredictor_5 (--/5.42k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/ClassPredictor (--/2.32k params)\n","      BoxPredictor_5/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x18, 2.30k/2.30k params)\n","  FeatureExtractor (--/4.48m params)\n","    FeatureExtractor/MobilenetV2 (--/4.48m params)\n","      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n","        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n","      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n","        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n","\n","======================End of Report==========================\n","135 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/13.71k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","\n","======================End of Report==========================\n","2020-05-28 07:28:36.558230: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-05-28 07:28:36.562658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:36.563487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-05-28 07:28:36.564022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-05-28 07:28:36.566167: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-05-28 07:28:36.567547: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-05-28 07:28:36.567952: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-05-28 07:28:36.570539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-05-28 07:28:36.572221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-05-28 07:28:36.577840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-05-28 07:28:36.578066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:36.578964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:36.580042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-05-28 07:28:36.580429: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2020-05-28 07:28:36.587153: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n","2020-05-28 07:28:36.587335: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2bcc840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-05-28 07:28:36.587362: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-05-28 07:28:36.675147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:36.675824: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2bccbc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-05-28 07:28:36.675857: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-05-28 07:28:36.676043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:36.676537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-05-28 07:28:36.676680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-05-28 07:28:36.676721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-05-28 07:28:36.676746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-05-28 07:28:36.676766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-05-28 07:28:36.676785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-05-28 07:28:36.676803: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-05-28 07:28:36.676823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-05-28 07:28:36.676900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:36.677423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:36.677934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-05-28 07:28:36.678007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-05-28 07:28:36.679121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-05-28 07:28:36.679151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-05-28 07:28:36.679161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-05-28 07:28:36.679280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:36.679850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:36.680315: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-05-28 07:28:36.680361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13099 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training_1/model.ckpt-2750\n","I0528 07:28:36.683410 140206724724608 saver.py:1284] Restoring parameters from training_1/model.ckpt-2750\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0528 07:28:39.487442 140206724724608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-05-28 07:28:39.950783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:39.951408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-05-28 07:28:39.951501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-05-28 07:28:39.951533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-05-28 07:28:39.951555: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-05-28 07:28:39.951612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-05-28 07:28:39.951647: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-05-28 07:28:39.951670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-05-28 07:28:39.951696: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-05-28 07:28:39.951794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:39.952344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:39.952803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-05-28 07:28:39.952845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-05-28 07:28:39.952858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-05-28 07:28:39.952868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-05-28 07:28:39.952972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:39.953482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:39.953962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13099 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training_1/model.ckpt-2750\n","I0528 07:28:39.955860 140206724724608 saver.py:1284] Restoring parameters from training_1/model.ckpt-2750\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0528 07:28:40.590240 140206724724608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0528 07:28:40.590514 140206724724608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 324 variables.\n","I0528 07:28:40.922608 140206724724608 graph_util_impl.py:334] Froze 324 variables.\n","INFO:tensorflow:Converted 324 variables to const ops.\n","I0528 07:28:40.996975 140206724724608 graph_util_impl.py:394] Converted 324 variables to const ops.\n","2020-05-28 07:28:41.155389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:41.155984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-05-28 07:28:41.156084: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-05-28 07:28:41.156120: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-05-28 07:28:41.156141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-05-28 07:28:41.156175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-05-28 07:28:41.156193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-05-28 07:28:41.156213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-05-28 07:28:41.156234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-05-28 07:28:41.156323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:41.156857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:41.157330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-05-28 07:28:41.157370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-05-28 07:28:41.157406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-05-28 07:28:41.157416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-05-28 07:28:41.157508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:41.158044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-28 07:28:41.158504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13099 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /gdrive/My Drive/object_detection/models/research/object_detection/exporter.py:326: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0528 07:28:41.679373 140206724724608 deprecation.py:323] From /gdrive/My Drive/object_detection/models/research/object_detection/exporter.py:326: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:No assets to save.\n","I0528 07:28:41.680083 140206724724608 builder_impl.py:640] No assets to save.\n","INFO:tensorflow:No assets to write.\n","I0528 07:28:41.680232 140206724724608 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: ./fine_tuned_model_1/saved_model/saved_model.pb\n","I0528 07:28:41.974826 140206724724608 builder_impl.py:425] SavedModel written to: ./fine_tuned_model_1/saved_model/saved_model.pb\n","INFO:tensorflow:Writing pipeline config file to ./fine_tuned_model_1/pipeline.config\n","I0528 07:28:42.001911 140206724724608 config_util.py:225] Writing pipeline config file to ./fine_tuned_model_1/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y63PSoVx4TQn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FYYcxN1gwwbi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ARVdC8FtwwZg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tW9WYbuCwwUe","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MGAg0so8vuQ0","colab_type":"text"},"source":["# 3. MODEL INFERENCING AND COUNTING THE PRODUCTS IN THE IMAGE"]},{"cell_type":"markdown","metadata":{"id":"kWPHANaujIYn","colab_type":"text"},"source":["**Inferencing the performance of the model and counting the number of products present**\n"]},{"cell_type":"code","metadata":{"id":"4rIuzBFJwLsV","colab_type":"code","colab":{}},"source":["import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","from pathlib import Path\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","from IPython.display import display"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4MIQBLxCyqhd","colab_type":"code","colab":{}},"source":["from object_detection.utils import ops as utils_ops\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QtUESEhEyt8m","colab_type":"code","colab":{}},"source":["# patch tf1 into `utils.ops`\n","utils_ops.tf = tf.compat.v1\n","# Patch the location of gfile\n","tf.gfile = tf.io.gfile"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OtF_gCYojuPi","colab_type":"text"},"source":["Running the below cells will load frozen inference graph from the fine tuned model which was previously saved after training."]},{"cell_type":"code","metadata":{"id":"WrEVIOAzy2Es","colab_type":"code","colab":{}},"source":["\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_FROZEN_GRAPH = '/gdrive/My Drive/object_detection/models/research/fine_tuned_model_1/frozen_inference_graph.pb'\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = \"/gdrive/My Drive/object_detection/images/label_map.pbtxt\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9miPRuf5y-Y6","colab_type":"code","colab":{}},"source":["detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1dXsakcUy-og","colab_type":"code","colab":{}},"source":["category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCmk8_Nuk1i4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S0rrn0lXkf3w","colab_type":"text"},"source":["If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS."]},{"cell_type":"code","metadata":{"id":"5KfsHT8fy-1Y","colab_type":"code","outputId":"fa737119-82c7-4e5d-9fcd-8ec2fcf7ee83","executionInfo":{"status":"ok","timestamp":1590650864187,"user_tz":-330,"elapsed":1116,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n","PATH_TO_TEST_IMAGES_DIR = Path('/gdrive/My Drive/object_detection/images/sample')\n","TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n","TEST_IMAGE_PATHS"],"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[PosixPath('/gdrive/My Drive/object_detection/images/sample/db1394.jpg'),\n"," PosixPath('/gdrive/My Drive/object_detection/images/sample/db1409.jpg'),\n"," PosixPath('/gdrive/My Drive/object_detection/images/sample/db280.jpg'),\n"," PosixPath('/gdrive/My Drive/object_detection/images/sample/db3099.jpg'),\n"," PosixPath('/gdrive/My Drive/object_detection/images/sample/db42.jpg'),\n"," PosixPath('/gdrive/My Drive/object_detection/images/sample/db605.jpg'),\n"," PosixPath('/gdrive/My Drive/object_detection/images/sample/db62.jpg'),\n"," PosixPath('/gdrive/My Drive/object_detection/images/sample/db828.jpg'),\n"," PosixPath('/gdrive/My Drive/object_detection/images/sample/db836.jpg'),\n"," PosixPath('/gdrive/My Drive/object_detection/images/sample/db837.jpg'),\n"," PosixPath('/gdrive/My Drive/object_detection/images/sample/db919.jpg'),\n"," PosixPath('/gdrive/My Drive/object_detection/images/sample/db939.jpg')]"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"id":"-VJVPUk85PfE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f2df9e87-3897-4d5b-f635-21b303ba630d","executionInfo":{"status":"ok","timestamp":1590646081232,"user_tz":-330,"elapsed":1104,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}}},"source":[""],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"2gYTNUx71f7r","colab_type":"code","colab":{}},"source":["def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LG-98J1X2xQJ","colab_type":"code","colab":{}},"source":["def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in ['num_detections', 'detection_boxes', 'detection_scores','detection_classes', 'detection_masks']:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(tensor_name)\n","                        \n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                 feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EUdRcgNbm9yA","colab_type":"text"},"source":["**Counting the products in the test images**"]},{"cell_type":"markdown","metadata":{"id":"CWK491ark-IJ","colab_type":"text"},"source":["The below cell will generate output for each image, this output contains detection class, detection scores, detection boxes.\n","\n","In order to know the number of prodcuts in each test image, we set the threshold on detection scores to 0.5, The total number of scores whose value greater than 0.5 is considered as a total number of prodcuts in the given image."]},{"cell_type":"markdown","metadata":{"id":"cNpQiQeUnKZm","colab_type":"text"},"source":["The first cell wil take a while to run, the subsequent cells will generate a json file having shelf_image_filename and product count as key and value."]},{"cell_type":"code","metadata":{"id":"6o4DUbo-8vrW","colab_type":"code","colab":{}},"source":["import numpy as np\n","shelf_images = {}\n","shelf_img_scores = {}\n","for image_path in TEST_IMAGE_PATHS:\n","    image = Image.open(image_path)\n","    name = str(image_path).split('/')[-1]\n","    image_np = load_image_into_numpy_array(image)\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    shelf_images['shelf_image_' + name] = int(np.sum(output_dict['detection_scores'] > 0.5))\n","    shelf_img_scores['shelf_image_' + name] = list(map(float, output_dict['detection_scores']))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FF58ub07MSY6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"2b29eff4-8323-41b1-e61d-52ebe6b4b138","executionInfo":{"status":"ok","timestamp":1590651077939,"user_tz":-330,"elapsed":1242,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}}},"source":["shelf_images"],"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'shelf_image_db1394.jpg': 1,\n"," 'shelf_image_db1409.jpg': 2,\n"," 'shelf_image_db280.jpg': 2,\n"," 'shelf_image_db3099.jpg': 3,\n"," 'shelf_image_db42.jpg': 2,\n"," 'shelf_image_db605.jpg': 2,\n"," 'shelf_image_db62.jpg': 2,\n"," 'shelf_image_db828.jpg': 2,\n"," 'shelf_image_db836.jpg': 2,\n"," 'shelf_image_db837.jpg': 3,\n"," 'shelf_image_db919.jpg': 4,\n"," 'shelf_image_db939.jpg': 3}"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"nTfDgffl_gUm","colab_type":"code","colab":{}},"source":["import json\n","with open('/gdrive/My Drive/image2products.json', 'w') as fp:\n","    json.dump(shelf_images, fp)\n","#with open('/gdrive/My Drive/scores2images.json', 'w') as ff:\n","#    json.dump(shelf_img_scores, ff)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KVoOy3Lg_lRR","colab_type":"code","outputId":"868e1878-6a17-449a-c72a-5b347172456b","executionInfo":{"status":"ok","timestamp":1588764452290,"user_tz":-330,"elapsed":943,"user":{"displayName":"yesu b m","photoUrl":"","userId":"00628767656634862234"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd '/gdrive/My Drive/'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bXteiFcE_lfT","colab_type":"code","colab":{}},"source":["from google.colab import files\n","files.download('image2products.json')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FVPJudFDWAQx","colab_type":"code","colab":{}},"source":["#files.download('scores2images.json') "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qv15E4g6wRlC","colab_type":"text"},"source":["**Run this cell to see the sample test images, where the boudning boxes are drawn.**"]},{"cell_type":"code","metadata":{"id":"YXS0yDuG4_V8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1xCZnkhHPa95fOCQbDHs8YKqjBFc2Cg9H"},"outputId":"f6a0b23c-a187-4a51-9908-3ec727c41a3d","executionInfo":{"status":"ok","timestamp":1590650950080,"user_tz":-330,"elapsed":63578,"user":{"displayName":"venkat sai","photoUrl":"","userId":"12601746592033760711"}}},"source":["%matplotlib inline\n","import numpy as np\n","IMAGE_SIZE = (10, 8)\n","shelf_images = {}\n","for image_path in TEST_IMAGE_PATHS:\n","    image = Image.open(image_path)\n","    name = str(image_path).split('/')[-1]\n","    image_np = load_image_into_numpy_array(image)\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","      image_np,\n","      output_dict['detection_boxes'],\n","      output_dict['detection_classes'],\n","      output_dict['detection_scores'],\n","      category_index,\n","      instance_masks=output_dict.get('detection_masks'),\n","      use_normalized_coordinates=True,\n","      line_thickness=8)\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image_np)"],"execution_count":76,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"A978lz3l5Gvq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}